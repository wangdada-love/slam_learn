# slam_learn
note and code of slam learning



# 概述
根据传感器的不同，机器人用的SLAM算法可以分为二维激光SLAM、三维激光SLAM，以及视觉SLAM。

其中，二维激光SLAM常用的有Cartographer、Karto，三维激光SLAM较流行的是LIO-SAM和LOAM系列，视觉SLAM主流的方案为ORB-SLAM3、VINS-Fusion……
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/2db417d7-178f-4419-897a-7595713b6dd4)

虽然各个算法细节不同,但都包含前端和后端.
## 前端
从传感器中获取原始数据，并将这些数据与已有地图进行关联，从而确定机器人轨迹的过程。

数据采集：通过传感器获取机器人周围环境的数据，如激光点云数据、图像数据等。
数据时空同步：将从不同传感器或不同时间戳接收到的数据进行同步，以便后续配准。
特征提取：从采集的数据中提取用于建图的特征点，如关键点、特征描述子等。
数据融合：将不同传感器获取的数据融合起来，提高建图的准确性和稳定性。
数据关联：将当前帧的特征与之前的地图，或者其他帧之间的特征进行匹配，以确定机器人的运动轨迹。
运动估计：通过数据关联得到机器人的运动轨迹，可以是平移、旋转等运动。

## 后端
根据前端获取的运动轨迹和地图信息，对机器人的状态、地图和传感器误差等进行估计和优化的过程。

非线性优化：通过非线性最小二乘法等，对机器人姿态和地图进行优化，使得机器人的位置和地图更加准确。
回环检测：识别机器人经过的相似位置，避免累积误差的产生。可以有效降低机器人的定位误差，提高SLAM算法的精度和鲁棒性。
后端优化的关键，是对整个系统的运动轨迹和地图进行全局优化，以消除积累误差和提高定位的准确性。

## 主流SLAM算法
### Cartographer
由谷歌开发的一款基于激光雷达和RGB-D相机数据的SLAM算法。可以跨平台使用，支持Lidar、IMU、Odemetry、GPS、Landmark等多种传感器配置，被广泛用于机器人导航、自动驾驶等领域。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/059cc363-363e-485f-85b4-b5b24a039953)

Cartographer算法在前端完成占据栅格地图的构建，得出激光雷达扫描帧的最佳位姿后，将扫描帧插入到子地图Submap中，得到局部优化的子地图并记录位姿。
后端根据扫描帧间的位姿关系进行全局的地图优化，并使用分支定界法加速求解，进而得出闭环扫描帧在全局地图中的最佳位姿。

### Karto
一种基于位姿图优化的SLAM方法，使用了高度优化和非迭代的cholesky矩阵对系统进行解耦并求解。适用于各种室内环境，可以处理静态和动态障碍物。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/ccd2f7fb-b277-4bd5-9259-b87820b460c8)

Karto使用图论的标准形式表示地图，其中每个节点代表了移动机器人运行轨迹上的一个位姿点，以及当前位姿下传感器返回的感知信息。
节点之间的边，代表了相邻机器人位姿之间的位移矢量。对每一个新的位姿点定位，需要节点间匹配关系和边带来的约束，保持定位估计误差的前后一致。

### LIO-SAM
一种新型的激光惯性导航系统，结合了激光雷达和惯性测量单元数据，可以实现机器人的高精度定位和运动轨迹的建图。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/90624254-6d26-4f21-998a-bad87cf6d17b)

前端在传统的LIDAR-SLAM基础上，利用卡尔曼滤波和因子图优化算法，将激光雷达和IMU数据融合，进一步提高机器人的定位精度和建图效果。后端加入优化算法，使得机器人的定位精度和建图精度都得到极大提升。

### LOAM系列
一种成熟的基于激光雷达的SLAM算法，包括LOAM、LOAM-Velodyne、LOAM-LiDAR等。

其中LOAM使用3D激光雷达的数据来进行建图和定位，利用点云数据的特征，如空间聚类、连续性约束等来估计位姿。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/5a5bef40-b5f5-4f6f-bbd5-972fab4e0008)

LOAM-Velodyne则使用Velodyne激光雷达的3D点云数据，以实现更高精度的地图重建和定位；LOAM-LiDAR采用LiDAR传感器来进行建图和定位，可以高效获取目标物体的三维坐标信息，在一些机器人应用场景具有很大的优势。

### ORB-SLAM3
当前最优秀的基于特征点的视觉SLAM系统之一，支持单目、双目、RBG-D等多种相机模式，在特征提取、关键帧选取、地图维护、位姿优化等方面进行了优化，并能建立短期、中期和长期的数据关联，使得该系统兼具精度和鲁棒性。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/694dc6c0-8075-4f9f-b249-8a27398405a3)

前端视觉里程计基于ORB特征，建立图像帧之间特征点的数据关联，以及图像特征点和地图点之间3D到2D的数据关联，具有较好的鲁棒性和提取效率，回环检测和重定位也基于ORB特征实现。

### VINS-Fusion
一种基于视觉惯性传感器的视觉SLAM算法。它将视觉和惯性信息进行融合，来提高机器人在未知环境下的定位和导航能力。
![image](https://github.com/wangdada-love/slam_learn/assets/80090934/fcdedd51-f4ac-4e50-aa26-029696efa110)

前端和后端之间通过一个状态传递机制来交换数据。前端将IMU和图像数据合并，生成一组状态量，然后将其传递给后端进行融合和优化；后端将优化后的状态量传递回前端，以便更新机器人的运动估计。
